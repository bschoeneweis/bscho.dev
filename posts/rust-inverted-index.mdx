---
title: 'Building an inverted index from scratch in Rust'
date: '2025-10-05'
tags: ['rust', 'search']
description: 'A brief primer on search, and building a simple inverted index from scratch in Rust, from tokenization to querying.'
---

Recently at [Radar](https://radar.com), I've been working on search (forward geocoding / autocomplete for addresses, POIs, and regions), and writing lots of Rust.

I thought it would be a fun exercise to write out some basics about general text-based search and also implement a simple inverted index (really only in Rust because I like the language a lot).  Let's dive in!

## A brief primer
An [inverted index](https://en.wikipedia.org/wiki/Inverted_index) is a fundamental data structure in the search world, powering text-based search for libraries like [Apache Lucene](https://lucene.apache.org/) and [Tantivy](https://github.com/quickwit-oss/tantivy).

To illustrate an inverted index, it's helpful to contrast with a [forward index](https://en.wikipedia.org/wiki/Search_engine_indexing#The_forward_index).

### Forward index

A forward index maps documents to the set of terms they contain:

| Document | Terms                                            |
| -------- | ------------------------------------------------ |
| 1        | the lord of the rings the fellowship of the ring |
| 2        | the lord of the rings the two towers             |
| 3        | the lord of the rings the return of the king     |
| ...      | ...                                              |
| 10       | star wars episode vi return of the jedi          |

Now imagine if we had a full catalog of movies, and we want to query for words in titles (or even something like scripts).  In a traditional forward index, that query might look something like:

```sql
SELECT * FROM movies WHERE title LIKE '%return%';
```

Due to the structure above, this query requires scanning over every document in the index and checking if the term exists in the title.  This can quickly get out of hand (especially with respect to latency) as datasets grow and grow (by row count, but also terms per document).

### Inverted index

An inverted index flips the forward index, and maps a set of terms to the documents they appear in:

| Term       | Documents   |
| ---------- | ----------- |
| episode    | 10          |
| fellowship | 1           |
| iv         | 10          |
| jedi       | 10          |
| king       | 3           |
| lord       | 1, 2, 3     |
| of         | 1, 2, 3, 10 |
| return     | 3, 10       |
| ring       | 1           |
| rings      | 1, 2, 3     |
| star       | 10          |
| the        | 1, 2, 3, 10 |
| towers     | 2           |
| two        | 2           |
| wars       | 10          |


Here we see each term mapped to the documents in which they appear.  Also notice that the index is sorted alphabetically by term (a small optimization).

The set of matching documents (the structure in the right column) is often called a **posting list** (or postings).

The other commonly associated structure with an inverted index is the **dictionary**.

The dictionary is the unique set of the terms that exists in the index.  It contains pointers from each term to its respective posting list (for fast lookups).  Since the posting lists can be quite large, dictionaries are often kept in-memory and point to the location of the posting list on disk.

Additional metadata such as **document frequency**, which tells us how many documents contain each term (also equal to the length of the posting list), may also be stored on the dictionary.  Document frequency can be helpful for ranking our documents after retrieval, which we will discuss more in a bit.

#### Searching
Instead of the full index scan that needs to occur with the forward index, we can now do a term-lookup in approximately constant time.  These faster lookups generally come at the cost of slower write speeds due to the complexity of the indexing (we'll dive into this later), but the faster reads generally outweigh the costs here.

For example, we can search for `"return"` and see that documents `3` and `10` have a match and return those documents.  This reduced our operation count from scanning `n` rows to reading the index and operating on the matching documents (which will almost always be much less than the total indexed rows).

#### Boolean operators
Since the result of the lookup is document ids (or the posting list), we can also take advantage of set operations (`AND`, `OR`, `NOT`) to introduce more powerful querying paradigms, such as expanding or narrowing our result set.

For example, we can support queries like `"rings" AND "return"` by doing lookups for both terms, and then taking the intersection of the matching documents: `[1, 2, 3] ∩ [3, 10] = [3]`.

We can do the same for `OR` queries: `"rings" OR "fellowship"` by taking the union: `[1, 2, 3] ∪ [1] = [1, 2, 3]`.

`NOT` queries can be supported by taking the set difference of _all_ of the document ids and the term posting list.  For example: `NOT "return"`: `[1, 2, 3, 10] \ [3, 10] = [1, 2]`.

#### Ranking
Ranking is the last topic we'll briefly cover before jumping into some code.  The lookups using our structure above help us to determine _which_ documents match given a term(s), but it doesn't tell us _how well_ they match (with respect to the rest of our data) to help us pick certain documents over other when retrieving.

##### Recall and precision
Before diving into ranking algorithms, it helps to discuss two fundamental terms in search: **recall** and **precision** (more in-depth definitions [here](https://en.wikipedia.org/wiki/Precision_and_recall)).

tl;dr is that:
- **Recall** is the proportion of relevant documents that were successfully retrieved.  Said otherwise, did we find all the documents that matter?
- **Precision** is the proportion of retrieved documents that are actually relevant.  Said otherwise, are the documents we returned, correct?

High recall means finding most of the relevant documents, even if some bad or irrelevant ones slip through.

High precision means your top results are highly relevant, even if you fail to fetch a few.

Balancing recall and precision is an art, but generally search systems aim to _retrieve_ results with high recall, and _rank_ by relevance to improve precision.

##### TF-IDF

One of the most fundamental ranking algorithms used in search is [TF-IDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf), or **Term Frequency-Inverse Document Frequency**.

This algorithm (while relatively simple) tries to tell us how important a term is in a document, across a collection or index of documents (also called a corpus).  The mathematics can be seen in the link above, but to provide a quick understanding, we can look at TF-IDF in two parts.

The first part of the algorithm is the **Term Frequency**.  This is a measurement of how often a term appears within a document.  Generally, the more often a term appears, the more important it is.

The second part is the **Inverse Document Frequency**.  This is a measurement of how often a term appears across the entire collection of documents.  In contrast, the _less_ a term appears across the corpus, the more significant it is.

For example, we can calculate the TF-IDF for two terms: `rings` and `fellowship` across a corpus of size `N = 4`.

The posting list for `rings` is `[1, 2, 3]`.  Given the occurrences, we can calculate the Term Frequency (TF):

| Document | Term Frequency (TF) | Total Terms | Normalized TF |
| -------- | -------------- | ----------- | ------------- |
| 1        | 1              | 9           | 1/9 ≈ 0.111   |
| 2        | 1              | 7           | 1/7 ≈ 0.143   |
| 3        | 1              | 8           | 1/8 = 0.125   |

Followed by the Inverse Document Frequency (IDF):

`IDF = log10(N / nₜ) = log10(4 / 3) ≈ 0.125`

Lastly, we do TF x IDF:

| Document | TF    | IDF   | TF-IDF |
| -------- | ----- | ----- | ------ |
| 1        | 0.111 | 0.125 | 0.0139 |
| 2        | 0.143 | 0.125 | 0.0179 |
| 3        | 0.125 | 0.125 | 0.0156 |

What exactly do these values mean?  Because the TF-IDF is smaller, than means the term `rings` (given our corpus), does not help us distinguish much between the documents.

Now let's contrast that with the more unique term, `fellowship`.

The posting list for `fellowship` is `[1]`.  With only a single occurence, we can still calculate the Term Frequency (TF):

| Document | Term Frequency (TF) | Total Terms | Normalized TF |
| -------- | -------------- | ----------- | ------------- |
| 1        | 1              | 9           | 1/9 ≈ 0.111   |

With the following IDF:

`IDF = log10(N / nₜ) = log10(4 / 1) ≈ 0.602`

Finishing with TF x IDF:

| Document | TF    | IDF   | TF-IDF |
| -------- | ----- | ----- | ------ |
| 1        | 0.111 | 0.602 | 0.0669 |

Even though these two terms have the same term frequency (primarily because the per-document text is small), `fellowship` has a much higher TF-IDF score, showing it's significance in _relevance_ between results.

Another common (and more evolved) ranking algorithm is [BM25](https://en.wikipedia.org/wiki/Okapi_BM25).  I won't cover it much here other than to say it addresses some shortcomings with TF-IDF, such as normalizing document length (you have one document that is significantly longer than another) and more.  BM25 is the more commonly used ranking algorithm in systems like Lucene and Tantivy.

---

To summarize the basics, with an inverted index plus some math, we can now:

- Retrieve documents efficiently by term
- Apply boolean operators (`AND`, `OR`, `NOT`) using set operations to narrow or widen the set of documents we retrieve
- Rank them by relevance (TF-IDF)


Now we can dive into a simple implementation to see what this looks like!

## Building the index

Let's start with the inverted index data structure itself:

```rust
use std::collections::{BTreeMap, HashMap};

type DocumentId = u32;
type Term = String;
type PostingList = Vec<DocumentId>;

#[derive(Debug)]
struct InvertedIndex {
    dictionary: BTreeMap<Term, PostingList>,
    term_frequencies: HashMap<DocumentId, HashMap<Term, usize>>,
    document_count: usize,
}

impl InvertedIndex {
    fn new() -> Self {
        Self {
            dictionary: BTreeMap::new(),
            term_frequencies: HashMap::new(),
            document_count: 0,
        }
    }
}
```

A few notes here:
- As shown in the inverted index example in the primer, we use a `BTreeMap` so our dictionary stays sorted and we get lookups ~`O(log n)`
- The posting list is a sort vector of document ids, this will enable fast set operations

### Indexing data
Let's take the documents from our example above and talk a little about indexing.

```rust
let documents = vec![
    "The Lord of the Rings: The Fellowship of the Ring",
    "The Lord of the Rings: The Two Towers",
    "The Lord of the Rings: The Return of the King",
    "Star Wars: Episode VI - Return of the Jedi",
];
```

#### Tokenization
An important part of indexing is **tokenization**.

Tokenization breaks the text into individual search "units" (usually called **tokens**), and normalizes each token for a consistent search experience.

This normalization could include operations like:
- Applying consistent casing
- Removing punctuation
- Removing [stop words](https://nlp.stanford.edu/IR-book/html/htmledition/dropping-common-terms-stop-words-1.html)
- [Stemming and lemmatization](https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html)
- Normalizing non-ascii character sets (e.g. [CJK characters](https://en.wikipedia.org/wiki/CJK_characters))
- Applying [n-grams](https://en.wikipedia.org/wiki/N-gram)
- And more

For the purposes of this article, we'll just look at the first few of these, but the other normalization techniques can make your simple search much more effective.

One of the most important aspects of tokenization is consistency between indexing and querying.  If you handle punctuation during indexing but not at query-time, you'll create mismatches.

For example, if you normalize `wasn't` -> `wasnt` during indexing, but you don't do the same when processing queries, then searching for `"wasn't"` won't match the term in the index.

Now let's add a tokenization function:

### The data structure

### Querying

### Improve performance

Sorted posting lists → enables binary search for intersections instead of contains().

Compression → delta encoding to reduce memory.

Multi-term queries → merge iterators instead of cloning vectors.

Stop words → ignore common words like “the”, “a”, “is”.